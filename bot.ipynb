{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1093eb0a0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1093eace0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='gemma2-9b-it', groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Venkat, it's nice to meet you!\\n\\nThat's great that you are a software engineer.  What kind of software engineering do you specialize in? \\n\\nI'm always interested in learning more about different areas of tech. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 22, 'total_tokens': 78, 'completion_time': 0.101818182, 'prompt_time': 0.002093411, 'queue_time': 0.245866038, 'total_time': 0.103911593}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--42cfe0db-00f4-4c1f-a96e-48098cf22f39-0', usage_metadata={'input_tokens': 22, 'output_tokens': 56, 'total_tokens': 78})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, i am venkat and i am a software enginner\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Venkat. üòä \\n\\nI remembered from our earlier conversation!  How can I help you today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 93, 'total_tokens': 119, 'completion_time': 0.047272727, 'prompt_time': 0.004204333, 'queue_time': 0.243797986, 'total_time': 0.05147706}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d94ecb24-84f3-43d9-8c09-d5dd72fec720-0', usage_metadata={'input_tokens': 93, 'output_tokens': 26, 'total_tokens': 119})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"Hi, i am venkat and i am a software enginner\"),\n",
    "    AIMessage(content=\"Hi Venkat,\\n\\nIt's nice to meet you! \\n\\nSoftware engineering is a fascinating field. What kind of software do you specialize in? \\n\\nDo you have any projects you're particularly proud of or working on that you'd like to talk about?\\n\"),\n",
    "    HumanMessage(content=\"What is my name?\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### message history\n",
    "###we need to make it statefull\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, i am venkat and i am a software enginner\")], config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Venkat, nice to meet you! üëã\\n\\nIt's great to know you're a software engineer. What kind of software engineering do you specialize in? üíª  \\n\\nDo you have any projects you're particularly proud of, or any areas of software development that you're particularly interested in? üòä\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Venkat.  üòä \\n\\nI remember that from our first exchange!  Is there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 103, 'total_tokens': 134, 'completion_time': 0.056363636, 'prompt_time': 0.005419745, 'queue_time': 0.24498034500000002, 'total_time': 0.061783381}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--fe37f44c-e7dd-4fcf-bda0-f9d220dfcaef-0', usage_metadata={'input_tokens': 103, 'output_tokens': 31, 'total_tokens': 134})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([\n",
    "    HumanMessage(content=\"What's my name?\")\n",
    "], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI, I have no memory of past conversations and do not know your name. Please tell me your name! üòä\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change session\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"Whats my name\")\n",
    "], config=config1)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John, it's nice to meet you! üëã\\n\\nIs there anything I can help you with today?\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\" my name is John\")\n",
    "], config=config1)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is John, as you told me earlier. üòä \\n\\nHow can I help you further? \\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"Whats my name\")\n",
    "], config=config1)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"you are a helpful assistant, Answer all the question to the nest of your ablility\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Venkat! üëã\\n\\nIt's nice to meet you. üòä\\n\\nWhat can I do for you today?  I'm ready to answer your questions to the best of my ability. Just ask! \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 33, 'total_tokens': 80, 'completion_time': 0.085454545, 'prompt_time': 0.002292393, 'queue_time': 0.245249516, 'total_time': 0.087746938}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3bf50063-b89b-4bfa-8850-5225da09dd10-0', usage_metadata={'input_tokens': 33, 'output_tokens': 47, 'total_tokens': 80})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"Hi my name is venkat\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Venkat!\\n\\nI'm happy to be your helpful assistant. Ask me anything, and I'll do my best to answer to the best of my ability. üòä  \\n\\nWhat can I help you with today? \\n\\n\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"my name is venkat\")\n",
    "], config= config)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Venkat. üòä \\n\\nI remember that from our introduction!  Is there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke([\n",
    "    HumanMessage(content=\"what is my name ?\")\n",
    "], config= config)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adding more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"you are a helpful assistant, Answer all the question to the nest of your ablility in {language}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§µ‡•á‡§Ç‡§ï‡§ü! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã‡§ó‡•Ä‡•§ ‡§Ü‡§™‡§ï‡•á ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à‡§Ç? \\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({ \"messages\": [ HumanMessage(content=\"Hi My name is venkat\") ], \"language\": \"Hindi\" }, config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets wrap the more complicated chain is a message history class. this time, because there are multiple keys in the input, we need to specify the correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§µ‡•á‡§Ç‡§ï‡§ü! üëã \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§Æ‡•á‡§∞‡•á ‡§∏‡§æ‡§• ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§  ‡§Ü‡§™‡§ï‡•á ‡§∏‡§µ‡§æ‡§≤‡•ã‡§Ç ‡§ï‡•á ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡•à‡§Ç ‡§Ö‡§™‡§®‡•Ä ‡§™‡•Ç‡§∞‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•Ç‡§Ç‡§ó‡§æ‡•§ \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? üòä\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Hi, I am Venkat\")],\n",
    "        \"language\": \"Hindi\"\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing the conversation History\n",
    "\n",
    "### add a step that limits the size of the messages you are passing in. \n",
    "'trim_messages' reduce how many messages we're sending to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='you are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi, I am bob', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanila ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(content=\"Hi, I am bob\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like vanila ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"What is 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said you like vanilla ice cream! üòä  \\n\\n\\n\\nAnything else I can help you with?\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What icecream do i like\")],\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2 + 2\" üòä \\n\\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What math problem did i ask?\")],\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets wrap this in the message history\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2 + 2\". \\n\\n\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What math problem did i ask?\")],\n",
    "    \"language\": \"English\"\n",
    "}, config=config)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.  You told me! üòä  \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What is my name?\")],\n",
    "    \"language\": \"English\"\n",
    "}, config=config)\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
